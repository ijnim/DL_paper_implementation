{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Segnet.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d7xrBmxb9B9V","outputId":"b2903c65-c01d-4d66-81c8-14833e6e9e5c","executionInfo":{"status":"ok","timestamp":1660538374174,"user_tz":-540,"elapsed":28079,"user":{"displayName":"민지","userId":"04260828416774580885"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from zipfile import *\n","import pandas as pd"],"metadata":{"id":"80dayVphzzLv","executionInfo":{"status":"ok","timestamp":1660538655847,"user_tz":-540,"elapsed":4,"user":{"displayName":"민지","userId":"04260828416774580885"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def ExtractZip(zipFile):\n","   archive = ZipFile.open(zipFile, 'r')\n","   archive.extractall()"],"metadata":{"id":"YMpBmM8W91e2","executionInfo":{"status":"ok","timestamp":1660538574144,"user_tz":-540,"elapsed":890,"user":{"displayName":"민지","userId":"04260828416774580885"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["my_zip = ZipFile('drive/MyDrive/CamVid.zip')"],"metadata":{"id":"HGWV0Eep-o3s","executionInfo":{"status":"ok","timestamp":1660538589634,"user_tz":-540,"elapsed":1967,"user":{"displayName":"민지","userId":"04260828416774580885"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["my_zip.extractall() #모든 파일 압축 해제"],"metadata":{"id":"5Snz9a5q-J6C","executionInfo":{"status":"ok","timestamp":1660538596848,"user_tz":-540,"elapsed":3955,"user":{"displayName":"민지","userId":"04260828416774580885"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"id":"GhZCjAuztzkg","executionInfo":{"status":"ok","timestamp":1660538627508,"user_tz":-540,"elapsed":2883,"user":{"displayName":"민지","userId":"04260828416774580885"}}},"outputs":[],"source":["from keras import backend as K\n","from keras.layers import Layer\n","\n","\n","class MaxPoolingWithArgmax2D(Layer):\n","    def __init__(self, pool_size=(2, 2), strides=(2, 2), padding=\"same\", **kwargs):\n","        super(MaxPoolingWithArgmax2D, self).__init__(**kwargs)\n","        self.padding = padding\n","        self.pool_size = pool_size\n","        self.strides = strides\n","\n","    def call(self, inputs, **kwargs):\n","        padding = self.padding\n","        pool_size = self.pool_size\n","        strides = self.strides\n","        if K.backend() == \"tensorflow\":\n","            ksize = [1, pool_size[0], pool_size[1], 1]\n","            padding = padding.upper()\n","            strides = [1, strides[0], strides[1], 1]\n","            output, argmax = K.tf.nn.max_pool_with_argmax(\n","                inputs, ksize=ksize, strides=strides, padding=padding\n","            )\n","        else:\n","            errmsg = \"{} backend is not supported for layer {}\".format(\n","                K.backend(), type(self).__name__\n","            )\n","            raise NotImplementedError(errmsg)\n","        argmax = K.cast(argmax, K.floatx())\n","        return [output, argmax]\n","\n","    def compute_output_shape(self, input_shape):\n","        ratio = (1, 2, 2, 1)\n","        output_shape = [\n","            dim // ratio[idx] if dim is not None else None\n","            for idx, dim in enumerate(input_shape)\n","        ]\n","        output_shape = tuple(output_shape)\n","        return [output_shape, output_shape]\n","\n","    def compute_mask(self, inputs, mask=None):\n","        return 2 * [None]\n","\n","\n","class MaxUnpooling2D(Layer):\n","    def __init__(self, size=(2, 2), **kwargs):\n","        super(MaxUnpooling2D, self).__init__(**kwargs)\n","        self.size = size\n","\n","    def call(self, inputs, output_shape=None):\n","        updates, mask = inputs[0], inputs[1]\n","        with K.tf.compat.v1.variable_scope(self.name):\n","            mask = K.cast(mask, \"int32\")\n","            input_shape = K.tf.shape(updates, out_type=\"int32\")\n","            #  calculation new shape\n","            if output_shape is None:\n","                output_shape = (\n","                    input_shape[0],\n","                    input_shape[1] * self.size[0],\n","                    input_shape[2] * self.size[1],\n","                    input_shape[3],\n","                )\n","            self.output_shape1 = output_shape\n","\n","            # calculation indices for batch, height, width and feature maps\n","            one_like_mask = K.ones_like(mask, dtype=\"int32\")\n","            batch_shape = K.concatenate([[input_shape[0]], [1], [1], [1]], axis=0)\n","            batch_range = K.reshape(\n","                K.tf.range(output_shape[0], dtype=\"int32\"), shape=batch_shape\n","            )\n","            b = one_like_mask * batch_range\n","            y = mask // (output_shape[2] * output_shape[3])\n","            x = (mask // output_shape[3]) % output_shape[2]\n","            feature_range = K.tf.range(output_shape[3], dtype=\"int32\")\n","            f = one_like_mask * feature_range\n","\n","            # transpose indices & reshape update values to one dimension\n","            updates_size = K.tf.size(updates)\n","            indices = K.transpose(K.reshape(K.stack([b, y, x, f]), [4, updates_size]))\n","            values = K.reshape(updates, [updates_size])\n","            ret = K.tf.scatter_nd(indices, values, output_shape)\n","            return ret\n","\n","    def compute_output_shape(self, input_shape):\n","        mask_shape = input_shape[1]\n","        return (\n","            mask_shape[0],\n","            mask_shape[1] * self.size[0],\n","            mask_shape[2] * self.size[1],\n","            mask_shape[3],\n","        )"]},{"cell_type":"code","source":["from keras.layers import Input\n","from keras.layers.convolutional import Convolution2D\n","from keras.layers.core import Activation, Reshape\n","from keras.layers import BatchNormalization\n","from keras.models import Model\n","\n","\n","def segnet(input_shape, n_labels, kernel=3, pool_size=(2, 2), output_mode=\"softmax\"):\n","    # encoder\n","    inputs = Input(shape=input_shape)\n","\n","    conv_1 = Convolution2D(64, (kernel, kernel), padding=\"same\")(inputs)\n","    conv_1 = BatchNormalization()(conv_1)\n","    conv_1 = Activation(\"relu\")(conv_1)\n","    conv_2 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_1)\n","    conv_2 = BatchNormalization()(conv_2)\n","    conv_2 = Activation(\"relu\")(conv_2)\n","\n","    pool_1, mask_1 = MaxPoolingWithArgmax2D(pool_size)(conv_2)\n","\n","    conv_3 = Convolution2D(128, (kernel, kernel), padding=\"same\")(pool_1)\n","    conv_3 = BatchNormalization()(conv_3)\n","    conv_3 = Activation(\"relu\")(conv_3)\n","    conv_4 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_3)\n","    conv_4 = BatchNormalization()(conv_4)\n","    conv_4 = Activation(\"relu\")(conv_4)\n","\n","    pool_2, mask_2 = MaxPoolingWithArgmax2D(pool_size)(conv_4)\n","\n","    conv_5 = Convolution2D(256, (kernel, kernel), padding=\"same\")(pool_2)\n","    conv_5 = BatchNormalization()(conv_5)\n","    conv_5 = Activation(\"relu\")(conv_5)\n","    conv_6 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_5)\n","    conv_6 = BatchNormalization()(conv_6)\n","    conv_6 = Activation(\"relu\")(conv_6)\n","    conv_7 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_6)\n","    conv_7 = BatchNormalization()(conv_7)\n","    conv_7 = Activation(\"relu\")(conv_7)\n","\n","    pool_3, mask_3 = MaxPoolingWithArgmax2D(pool_size)(conv_7)\n","\n","    conv_8 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_3)\n","    conv_8 = BatchNormalization()(conv_8)\n","    conv_8 = Activation(\"relu\")(conv_8)\n","    conv_9 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_8)\n","    conv_9 = BatchNormalization()(conv_9)\n","    conv_9 = Activation(\"relu\")(conv_9)\n","    conv_10 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_9)\n","    conv_10 = BatchNormalization()(conv_10)\n","    conv_10 = Activation(\"relu\")(conv_10)\n","\n","    pool_4, mask_4 = MaxPoolingWithArgmax2D(pool_size)(conv_10)\n","\n","    conv_11 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_4)\n","    conv_11 = BatchNormalization()(conv_11)\n","    conv_11 = Activation(\"relu\")(conv_11)\n","    conv_12 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_11)\n","    conv_12 = BatchNormalization()(conv_12)\n","    conv_12 = Activation(\"relu\")(conv_12)\n","    conv_13 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_12)\n","    conv_13 = BatchNormalization()(conv_13)\n","    conv_13 = Activation(\"relu\")(conv_13)\n","\n","    pool_5, mask_5 = MaxPoolingWithArgmax2D(pool_size)(conv_13)\n","    print(\"Build enceder done..\")\n","\n","    # decoder\n","\n","    unpool_1 = MaxUnpooling2D(pool_size)([pool_5, mask_5])\n","\n","    conv_14 = Convolution2D(512, (kernel, kernel), padding=\"same\")(unpool_1)\n","    conv_14 = BatchNormalization()(conv_14)\n","    conv_14 = Activation(\"relu\")(conv_14)\n","    conv_15 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_14)\n","    conv_15 = BatchNormalization()(conv_15)\n","    conv_15 = Activation(\"relu\")(conv_15)\n","    conv_16 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_15)\n","    conv_16 = BatchNormalization()(conv_16)\n","    conv_16 = Activation(\"relu\")(conv_16)\n","\n","    unpool_2 = MaxUnpooling2D(pool_size)([conv_16, mask_4])\n","\n","    conv_17 = Convolution2D(512, (kernel, kernel), padding=\"same\")(unpool_2)\n","    conv_17 = BatchNormalization()(conv_17)\n","    conv_17 = Activation(\"relu\")(conv_17)\n","    conv_18 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_17)\n","    conv_18 = BatchNormalization()(conv_18)\n","    conv_18 = Activation(\"relu\")(conv_18)\n","    conv_19 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_18)\n","    conv_19 = BatchNormalization()(conv_19)\n","    conv_19 = Activation(\"relu\")(conv_19)\n","\n","    unpool_3 = MaxUnpooling2D(pool_size)([conv_19, mask_3])\n","\n","    conv_20 = Convolution2D(256, (kernel, kernel), padding=\"same\")(unpool_3)\n","    conv_20 = BatchNormalization()(conv_20)\n","    conv_20 = Activation(\"relu\")(conv_20)\n","    conv_21 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_20)\n","    conv_21 = BatchNormalization()(conv_21)\n","    conv_21 = Activation(\"relu\")(conv_21)\n","    conv_22 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_21)\n","    conv_22 = BatchNormalization()(conv_22)\n","    conv_22 = Activation(\"relu\")(conv_22)\n","\n","    unpool_4 = MaxUnpooling2D(pool_size)([conv_22, mask_2])\n","\n","    conv_23 = Convolution2D(128, (kernel, kernel), padding=\"same\")(unpool_4)\n","    conv_23 = BatchNormalization()(conv_23)\n","    conv_23 = Activation(\"relu\")(conv_23)\n","    conv_24 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_23)\n","    conv_24 = BatchNormalization()(conv_24)\n","    conv_24 = Activation(\"relu\")(conv_24)\n","\n","    unpool_5 = MaxUnpooling2D(pool_size)([conv_24, mask_1])\n","\n","    conv_25 = Convolution2D(64, (kernel, kernel), padding=\"same\")(unpool_5)\n","    conv_25 = BatchNormalization()(conv_25)\n","    conv_25 = Activation(\"relu\")(conv_25)\n","\n","    conv_26 = Convolution2D(n_labels, (1, 1), padding=\"valid\")(conv_25)\n","    conv_26 = BatchNormalization()(conv_26)\n","    conv_26 = Reshape(\n","        (input_shape[0] * input_shape[1], n_labels),\n","        input_shape=(input_shape[0], input_shape[1], n_labels),\n","    )(conv_26)\n","\n","    outputs = Activation(output_mode)(conv_26)\n","    print(\"Build decoder done..\")\n","\n","    model = Model(inputs=inputs, outputs=outputs, name=\"SegNet\")\n","\n","    return model"],"metadata":{"id":"MshwD-Yzt1A6","executionInfo":{"status":"ok","timestamp":1660538633899,"user_tz":-540,"elapsed":480,"user":{"displayName":"민지","userId":"04260828416774580885"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["classdict=pd.read_csv('CamVid/class_dict.csv',index_col=0)"],"metadata":{"id":"aFlkzRYHPbDV","colab":{"base_uri":"https://localhost:8080/","height":345},"executionInfo":{"status":"error","timestamp":1660538659726,"user_tz":-540,"elapsed":8,"user":{"displayName":"민지","userId":"04260828416774580885"}},"outputId":"bec4c134-ff2d-456e-803f-083d1dd12be8"},"execution_count":16,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-3461c7c65159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassdict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CamVid/class_dict.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CamVid/class_dict.csv'"]}]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","\n","from keras.preprocessing.image import img_to_array\n","\n","#Mask를 Categorical Array로 만드는 과정\n","def adjust_mask(mask, classes = classdict, flat=True):\n","    cls2rgb = {cl:list(classes.loc[cl, :]) for cl in classes.index}\n","    semantic_map = []\n","    for colour in list(cls2rgb.values()):        \n","        equality = np.equal(mask, colour)# 256x256x3 with True or False\n","        class_map = np.all(equality, axis = -1)# 256x256 If all True, then True, else False\n","        semantic_map.append(class_map)# List of 256x256 arrays, map of True for a given found color at the pixel, and False otherwise.\n","    semantic_map = np.stack(semantic_map, axis=-1)# 256x256x32 True only at the found color, and all False otherwise.\n","    if flat:\n","      semantic_map = np.reshape(semantic_map, (256*256,-1))\n","\n","    return np.float32(semantic_map)# convert to numbers\n","\n","'''def category_label(labels, dims, n_labels):\n","    x = np.zeros([dims[0], dims[1], n_labels])\n","    for i in range(dims[0]):\n","        for j in range(dims[1]):\n","          if x[i,j,:] == \n","            x[i, j, labels[i][j]] = 1\n","    x = x.reshape(dims[0] * dims[1], n_labels)\n","    return x'''\n","\n","\n","def data_gen_small(img_dir, mask_dir, lists, batch_size, dims, n_labels):\n","    while True:\n","        ix = np.random.choice(np.arange(len(lists)), batch_size)\n","        imgs = []\n","        labels = []\n","        for i in ix:\n","            # images\n","            img_path = img_dir + lists.iloc[i, 0] + \".jpg\"\n","            original_img = cv2.imread(img_path)[:, :, ::-1]\n","            resized_img = cv2.resize(original_img, dims + [3])\n","            array_img = img_to_array(resized_img) / 255\n","            imgs.append(array_img)\n","            # masks\n","            original_mask = cv2.imread(mask_dir + lists.iloc[i, 0] + \".png\")\n","            resized_mask = cv2.resize(original_mask, (dims[0], dims[1]))\n","            array_mask = category_label(resized_mask[:, :, 0], dims, n_labels)\n","            labels.append(array_mask)\n","        imgs = np.array(imgs)\n","        labels = np.array(labels)\n","        yield imgs, labels\n","\n","#내 데이터에 맞춘 generator\n","def data_gen_small_me(img_lists, msk_lists, batch_size, dims, n_labels):\n","    while True:\n","        ix = np.random.choice(np.arange(len(img_lists)), batch_size)\n","        imgs = []\n","        labels = []\n","        for i in ix:\n","            # images\n","            img_path = img_lists[i]\n","            original_img = cv2.imread(img_path)[:, :, ::-1]\n","            resized_img = cv2.resize(original_img[:2], dims)\n","            array_img = img_to_array(resized_img) / 255\n","            imgs.append(array_img)\n","            # masks\n","            original_mask = cv2.imread(msk_lists[i])\n","            resized_mask = cv2.resize(original_mask, (dims[0], dims[1]))\n","            array_mask = adjust_mask(resized_mask)\n","            labels.append(array_mask)\n","        imgs = np.array(imgs)\n","        labels = np.array(labels)\n","        yield imgs, labels"],"metadata":{"id":"BTm7AkKyt9L0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","dir_path = \"CamVid/train\"\n","\n","def oswalk(dir_path):\n","  paths=[]\n","  for (root, directories, files) in os.walk(dir_path):\n","      for file in files:\n","          if '.png' in file:\n","              path = os.path.join(root, file)\n","              paths.append(path)\n","  return paths\n","\n","train_path = oswalk(\"CamVid/train\")\n","test_path = oswalk(\"CamVid/test\")\n","val_path = oswalk(\"CamVid/val\")\n","trainL_path = oswalk(\"CamVid/train_labels\")\n","testL_path = oswalk(\"CamVid/test_labels\")\n","valL_path = oswalk(\"CamVid/val_labels\")"],"metadata":{"id":"y2E0Aw9DAAvQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import easydict\n","#코랩 전용 parameter넣기\n","args = easydict.EasyDict({\n","        \"save_dir\" : \"\",\n","        \"train_list\" : train_path,\n","        \"trainL_list\" : trainL_path,\n","        \"trainimg_dir\" : \"CamVid/train\",\n","        \"trainmsk_dir\" : \"CamVid/train_labels\",\n","        \"val_list\" : test_path,\n","        \"valL_list\" : testL_path,\n","        \"valimg_dir\" : \"CamVid/test\",\n","        \"valmsk_dir\" : \"CamVid/test_labels\",\n","        \"batch_size\" : 10,\n","        \"n_epochs\" : 10,\n","        \"epoch_steps\" : 10,\n","        \"val_steps\" : 10,\n","        \"n_labels\" : 32,\n","        \"input_shape\" : (256, 256, 3),\n","        \"pool_size\" : (2, 2),\n","        \"output_mode\" : \"softmax\",\n","        \"loss\" : \"categorical_crossentropy\",\n","        \"optimizer\" : \"adadelta\",\n","        \"kernel\" : 3,\n","    })"],"metadata":{"id":"q2ssgVQaDssO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import argparse\n","\n","import pandas as pd\n","\n","\n","'''def argparser():\n","    # command line argments\n","    parser = argparse.ArgumentParser(description=\"SegNet LIP dataset\")\n","    parser.add_argument(\"--save_dir\", help=\"output directory\")\n","    parser.add_argument(\"--train_list\", help=\"train list path\",default = train_path_data)\n","    parser.add_argument(\"--trainimg_dir\", help=\"train image dir path\",default=\"CamVid/train\")\n","    parser.add_argument(\"--trainmsk_dir\", help=\"train mask dir path\",default=\"CamVid/train_labels\")\n","    parser.add_argument(\"--val_list\", help=\"val list path\",default = test_path_data)\n","    parser.add_argument(\"--valimg_dir\", help=\"val image dir path\",default = \"CamVid/test\")\n","    parser.add_argument(\"--valmsk_dir\", help=\"val mask dir path\",default = \"CamVid/test_labels\")\n","    parser.add_argument(\"--batch_size\", default=10, type=int, help=\"batch size\")\n","    parser.add_argument(\"--n_epochs\", default=10, type=int, help=\"number of epoch\")\n","    parser.add_argument(\n","        \"--epoch_steps\", default=100, type=int, help=\"number of epoch step\"\n","    )\n","    parser.add_argument(\n","        \"--val_steps\", default=10, type=int, help=\"number of valdation step\"\n","    )\n","    parser.add_argument(\"--n_labels\", default=20, type=int, help=\"Number of label\")\n","    parser.add_argument(\n","        \"--input_shape\", default=(256, 256, 3), help=\"Input images shape\"\n","    )\n","    parser.add_argument(\"--kernel\", default=3, type=int, help=\"Kernel size\")\n","    parser.add_argument(\n","        \"--pool_size\", default=(2, 2), help=\"pooling and unpooling size\"\n","    )\n","    parser.add_argument(\n","        \"--output_mode\", default=\"softmax\", type=str, help=\"output activation\"\n","    )\n","    parser.add_argument(\n","        \"--loss\", default=\"categorical_crossentropy\", type=str, help=\"loss function\"\n","    )\n","    parser.add_argument(\"--optimizer\", default=\"adadelta\", type=str, help=\"oprimizer\")\n","    args = parser.parse_args()\n","\n","    return args'''\n","\n","\n","def main(args):\n","    # set the necessary list\n","    train_list=args.train_list\n","    val_list = args.val_list\n","    trainL_list=args.trainL_list\n","    valL_list = args.valL_list\n","    #train_list = pd.read_csv(args.train_list, header=None)\n","    #val_list = pd.read_csv(args.val_list, header=None)\n","\n","    # set the necessary directories\n","    trainimg_dir = args.trainimg_dir\n","    trainmsk_dir = args.trainmsk_dir\n","    valimg_dir = args.valimg_dir\n","    valmsk_dir = args.valmsk_dir\n","\n","    train_gen = data_gen_small_me(\n","        train_list,\n","        trainL_list,\n","        args.batch_size,\n","        [args.input_shape[0], args.input_shape[1]],\n","        args.n_labels,\n","    )\n","    val_gen = data_gen_small_me(\n","        val_list,\n","        valL_list,\n","        args.batch_size,\n","        [args.input_shape[0], args.input_shape[1]],\n","        args.n_labels,\n","    )\n","\n","    model = segnet(\n","        args.input_shape, args.n_labels, args.kernel, args.pool_size, args.output_mode\n","    )\n","    print(model.summary())\n","\n","    model.compile(loss=args.loss, optimizer=args.optimizer, metrics=[\"accuracy\"])\n","    model.fit_generator(\n","        train_gen,\n","        steps_per_epoch=args.epoch_steps,\n","        epochs=args.n_epochs,\n","        validation_data=val_gen,\n","        validation_steps=args.val_steps,\n","    )\n","\n","    model.save_weights(args.save_dir + str(args.n_epochs) + \".hdf5\")\n","    print(\"sava weight done..\")\n","\n","\n","if __name__ == \"__main__\":\n","    main(args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5JgPkuyiuZn1","outputId":"e430a7db-e234-4cdc-aca9-86a3f8f7aed7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Build enceder done..\n","Build decoder done..\n","Model: \"SegNet\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_12 (InputLayer)          [(None, 256, 256, 3  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d_273 (Conv2D)            (None, 256, 256, 64  1792        ['input_12[0][0]']               \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_273 (Batch  (None, 256, 256, 64  256        ['conv2d_273[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," activation_273 (Activation)    (None, 256, 256, 64  0           ['batch_normalization_273[0][0]']\n","                                )                                                                 \n","                                                                                                  \n"," conv2d_274 (Conv2D)            (None, 256, 256, 64  36928       ['activation_273[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_274 (Batch  (None, 256, 256, 64  256        ['conv2d_274[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," activation_274 (Activation)    (None, 256, 256, 64  0           ['batch_normalization_274[0][0]']\n","                                )                                                                 \n","                                                                                                  \n"," max_pooling_with_argmax2d_55 (  [(None, 128, 128, 6  0          ['activation_274[0][0]']         \n"," MaxPoolingWithArgmax2D)        4),                                                               \n","                                 (None, 128, 128, 6                                               \n","                                4)]                                                               \n","                                                                                                  \n"," conv2d_275 (Conv2D)            (None, 128, 128, 12  73856       ['max_pooling_with_argmax2d_55[0]\n","                                8)                               [0]']                            \n","                                                                                                  \n"," batch_normalization_275 (Batch  (None, 128, 128, 12  512        ['conv2d_275[0][0]']             \n"," Normalization)                 8)                                                                \n","                                                                                                  \n"," activation_275 (Activation)    (None, 128, 128, 12  0           ['batch_normalization_275[0][0]']\n","                                8)                                                                \n","                                                                                                  \n"," conv2d_276 (Conv2D)            (None, 128, 128, 12  147584      ['activation_275[0][0]']         \n","                                8)                                                                \n","                                                                                                  \n"," batch_normalization_276 (Batch  (None, 128, 128, 12  512        ['conv2d_276[0][0]']             \n"," Normalization)                 8)                                                                \n","                                                                                                  \n"," activation_276 (Activation)    (None, 128, 128, 12  0           ['batch_normalization_276[0][0]']\n","                                8)                                                                \n","                                                                                                  \n"," max_pooling_with_argmax2d_56 (  [(None, 64, 64, 128  0          ['activation_276[0][0]']         \n"," MaxPoolingWithArgmax2D)        ),                                                                \n","                                 (None, 64, 64, 128                                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d_277 (Conv2D)            (None, 64, 64, 256)  295168      ['max_pooling_with_argmax2d_56[0]\n","                                                                 [0]']                            \n","                                                                                                  \n"," batch_normalization_277 (Batch  (None, 64, 64, 256)  1024       ['conv2d_277[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_277 (Activation)    (None, 64, 64, 256)  0           ['batch_normalization_277[0][0]']\n","                                                                                                  \n"," conv2d_278 (Conv2D)            (None, 64, 64, 256)  590080      ['activation_277[0][0]']         \n","                                                                                                  \n"," batch_normalization_278 (Batch  (None, 64, 64, 256)  1024       ['conv2d_278[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_278 (Activation)    (None, 64, 64, 256)  0           ['batch_normalization_278[0][0]']\n","                                                                                                  \n"," conv2d_279 (Conv2D)            (None, 64, 64, 256)  590080      ['activation_278[0][0]']         \n","                                                                                                  \n"," batch_normalization_279 (Batch  (None, 64, 64, 256)  1024       ['conv2d_279[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_279 (Activation)    (None, 64, 64, 256)  0           ['batch_normalization_279[0][0]']\n","                                                                                                  \n"," max_pooling_with_argmax2d_57 (  [(None, 32, 32, 256  0          ['activation_279[0][0]']         \n"," MaxPoolingWithArgmax2D)        ),                                                                \n","                                 (None, 32, 32, 256                                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d_280 (Conv2D)            (None, 32, 32, 512)  1180160     ['max_pooling_with_argmax2d_57[0]\n","                                                                 [0]']                            \n","                                                                                                  \n"," batch_normalization_280 (Batch  (None, 32, 32, 512)  2048       ['conv2d_280[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_280 (Activation)    (None, 32, 32, 512)  0           ['batch_normalization_280[0][0]']\n","                                                                                                  \n"," conv2d_281 (Conv2D)            (None, 32, 32, 512)  2359808     ['activation_280[0][0]']         \n","                                                                                                  \n"," batch_normalization_281 (Batch  (None, 32, 32, 512)  2048       ['conv2d_281[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_281 (Activation)    (None, 32, 32, 512)  0           ['batch_normalization_281[0][0]']\n","                                                                                                  \n"," conv2d_282 (Conv2D)            (None, 32, 32, 512)  2359808     ['activation_281[0][0]']         \n","                                                                                                  \n"," batch_normalization_282 (Batch  (None, 32, 32, 512)  2048       ['conv2d_282[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_282 (Activation)    (None, 32, 32, 512)  0           ['batch_normalization_282[0][0]']\n","                                                                                                  \n"," max_pooling_with_argmax2d_58 (  [(None, 16, 16, 512  0          ['activation_282[0][0]']         \n"," MaxPoolingWithArgmax2D)        ),                                                                \n","                                 (None, 16, 16, 512                                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d_283 (Conv2D)            (None, 16, 16, 512)  2359808     ['max_pooling_with_argmax2d_58[0]\n","                                                                 [0]']                            \n","                                                                                                  \n"," batch_normalization_283 (Batch  (None, 16, 16, 512)  2048       ['conv2d_283[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_283 (Activation)    (None, 16, 16, 512)  0           ['batch_normalization_283[0][0]']\n","                                                                                                  \n"," conv2d_284 (Conv2D)            (None, 16, 16, 512)  2359808     ['activation_283[0][0]']         \n","                                                                                                  \n"," batch_normalization_284 (Batch  (None, 16, 16, 512)  2048       ['conv2d_284[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_284 (Activation)    (None, 16, 16, 512)  0           ['batch_normalization_284[0][0]']\n","                                                                                                  \n"," conv2d_285 (Conv2D)            (None, 16, 16, 512)  2359808     ['activation_284[0][0]']         \n","                                                                                                  \n"," batch_normalization_285 (Batch  (None, 16, 16, 512)  2048       ['conv2d_285[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_285 (Activation)    (None, 16, 16, 512)  0           ['batch_normalization_285[0][0]']\n","                                                                                                  \n"," max_pooling_with_argmax2d_59 (  [(None, 8, 8, 512),  0          ['activation_285[0][0]']         \n"," MaxPoolingWithArgmax2D)         (None, 8, 8, 512)]                                               \n","                                                                                                  \n"," max_unpooling2d_51 (MaxUnpooli  (None, 16, 16, 512)  0          ['max_pooling_with_argmax2d_59[0]\n"," ng2D)                                                           [0]',                            \n","                                                                  'max_pooling_with_argmax2d_59[0]\n","                                                                 [1]']                            \n","                                                                                                  \n"," conv2d_286 (Conv2D)            (None, 16, 16, 512)  2359808     ['max_unpooling2d_51[0][0]']     \n","                                                                                                  \n"," batch_normalization_286 (Batch  (None, 16, 16, 512)  2048       ['conv2d_286[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_286 (Activation)    (None, 16, 16, 512)  0           ['batch_normalization_286[0][0]']\n","                                                                                                  \n"," conv2d_287 (Conv2D)            (None, 16, 16, 512)  2359808     ['activation_286[0][0]']         \n","                                                                                                  \n"," batch_normalization_287 (Batch  (None, 16, 16, 512)  2048       ['conv2d_287[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_287 (Activation)    (None, 16, 16, 512)  0           ['batch_normalization_287[0][0]']\n","                                                                                                  \n"," conv2d_288 (Conv2D)            (None, 16, 16, 512)  2359808     ['activation_287[0][0]']         \n","                                                                                                  \n"," batch_normalization_288 (Batch  (None, 16, 16, 512)  2048       ['conv2d_288[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_288 (Activation)    (None, 16, 16, 512)  0           ['batch_normalization_288[0][0]']\n","                                                                                                  \n"," max_unpooling2d_52 (MaxUnpooli  (None, 32, 32, 512)  0          ['activation_288[0][0]',         \n"," ng2D)                                                            'max_pooling_with_argmax2d_58[0]\n","                                                                 [1]']                            \n","                                                                                                  \n"," conv2d_289 (Conv2D)            (None, 32, 32, 512)  2359808     ['max_unpooling2d_52[0][0]']     \n","                                                                                                  \n"," batch_normalization_289 (Batch  (None, 32, 32, 512)  2048       ['conv2d_289[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_289 (Activation)    (None, 32, 32, 512)  0           ['batch_normalization_289[0][0]']\n","                                                                                                  \n"," conv2d_290 (Conv2D)            (None, 32, 32, 512)  2359808     ['activation_289[0][0]']         \n","                                                                                                  \n"," batch_normalization_290 (Batch  (None, 32, 32, 512)  2048       ['conv2d_290[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_290 (Activation)    (None, 32, 32, 512)  0           ['batch_normalization_290[0][0]']\n","                                                                                                  \n"," conv2d_291 (Conv2D)            (None, 32, 32, 256)  1179904     ['activation_290[0][0]']         \n","                                                                                                  \n"," batch_normalization_291 (Batch  (None, 32, 32, 256)  1024       ['conv2d_291[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_291 (Activation)    (None, 32, 32, 256)  0           ['batch_normalization_291[0][0]']\n","                                                                                                  \n"," max_unpooling2d_53 (MaxUnpooli  (None, 64, 64, 256)  0          ['activation_291[0][0]',         \n"," ng2D)                                                            'max_pooling_with_argmax2d_57[0]\n","                                                                 [1]']                            \n","                                                                                                  \n"," conv2d_292 (Conv2D)            (None, 64, 64, 256)  590080      ['max_unpooling2d_53[0][0]']     \n","                                                                                                  \n"," batch_normalization_292 (Batch  (None, 64, 64, 256)  1024       ['conv2d_292[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_292 (Activation)    (None, 64, 64, 256)  0           ['batch_normalization_292[0][0]']\n","                                                                                                  \n"," conv2d_293 (Conv2D)            (None, 64, 64, 256)  590080      ['activation_292[0][0]']         \n","                                                                                                  \n"," batch_normalization_293 (Batch  (None, 64, 64, 256)  1024       ['conv2d_293[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_293 (Activation)    (None, 64, 64, 256)  0           ['batch_normalization_293[0][0]']\n","                                                                                                  \n"," conv2d_294 (Conv2D)            (None, 64, 64, 128)  295040      ['activation_293[0][0]']         \n","                                                                                                  \n"," batch_normalization_294 (Batch  (None, 64, 64, 128)  512        ['conv2d_294[0][0]']             \n"," Normalization)                                                                                   \n","                                                                                                  \n"," activation_294 (Activation)    (None, 64, 64, 128)  0           ['batch_normalization_294[0][0]']\n","                                                                                                  \n"," max_unpooling2d_54 (MaxUnpooli  (None, 128, 128, 12  0          ['activation_294[0][0]',         \n"," ng2D)                          8)                                'max_pooling_with_argmax2d_56[0]\n","                                                                 [1]']                            \n","                                                                                                  \n"," conv2d_295 (Conv2D)            (None, 128, 128, 12  147584      ['max_unpooling2d_54[0][0]']     \n","                                8)                                                                \n","                                                                                                  \n"," batch_normalization_295 (Batch  (None, 128, 128, 12  512        ['conv2d_295[0][0]']             \n"," Normalization)                 8)                                                                \n","                                                                                                  \n"," activation_295 (Activation)    (None, 128, 128, 12  0           ['batch_normalization_295[0][0]']\n","                                8)                                                                \n","                                                                                                  \n"," conv2d_296 (Conv2D)            (None, 128, 128, 64  73792       ['activation_295[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_296 (Batch  (None, 128, 128, 64  256        ['conv2d_296[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," activation_296 (Activation)    (None, 128, 128, 64  0           ['batch_normalization_296[0][0]']\n","                                )                                                                 \n","                                                                                                  \n"," max_unpooling2d_55 (MaxUnpooli  (None, 256, 256, 64  0          ['activation_296[0][0]',         \n"," ng2D)                          )                                 'max_pooling_with_argmax2d_55[0]\n","                                                                 [1]']                            \n","                                                                                                  \n"," conv2d_297 (Conv2D)            (None, 256, 256, 64  36928       ['max_unpooling2d_55[0][0]']     \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_297 (Batch  (None, 256, 256, 64  256        ['conv2d_297[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," activation_297 (Activation)    (None, 256, 256, 64  0           ['batch_normalization_297[0][0]']\n","                                )                                                                 \n","                                                                                                  \n"," conv2d_298 (Conv2D)            (None, 256, 256, 32  2080        ['activation_297[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_298 (Batch  (None, 256, 256, 32  128        ['conv2d_298[0][0]']             \n"," Normalization)                 )                                                                 \n","                                                                                                  \n"," reshape_10 (Reshape)           (None, 65536, 32)    0           ['batch_normalization_298[0][0]']\n","                                                                                                  \n"," activation_298 (Activation)    (None, 65536, 32)    0           ['reshape_10[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 29,461,088\n","Trainable params: 29,445,152\n","Non-trainable params: 15,936\n","__________________________________________________________________________________________________\n","None\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:85: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","10/10 [==============================] - 42s 4s/step - loss: 1.9529 - accuracy: 0.0293 - val_loss: 1.7343 - val_accuracy: 0.0018\n","Epoch 2/10\n","10/10 [==============================] - 30s 3s/step - loss: 1.9742 - accuracy: 0.0294 - val_loss: 1.7728 - val_accuracy: 0.0020\n","Epoch 3/10\n","10/10 [==============================] - 28s 3s/step - loss: 2.0326 - accuracy: 0.0289 - val_loss: 1.8140 - val_accuracy: 0.0020\n","Epoch 4/10\n","10/10 [==============================] - 28s 3s/step - loss: 1.9465 - accuracy: 0.0289 - val_loss: 1.7712 - val_accuracy: 0.0019\n","Epoch 5/10\n","10/10 [==============================] - 28s 3s/step - loss: 1.9646 - accuracy: 0.0285 - val_loss: 1.8359 - val_accuracy: 0.0018\n","Epoch 6/10\n","10/10 [==============================] - 28s 3s/step - loss: 1.9623 - accuracy: 0.0279 - val_loss: 1.8116 - val_accuracy: 0.0018\n","Epoch 7/10\n","10/10 [==============================] - 29s 3s/step - loss: 1.9127 - accuracy: 0.0287 - val_loss: 1.7935 - val_accuracy: 0.0019\n","Epoch 8/10\n","10/10 [==============================] - 28s 3s/step - loss: 1.9826 - accuracy: 0.0287 - val_loss: 1.8999 - val_accuracy: 0.0018\n","Epoch 9/10\n","10/10 [==============================] - 28s 3s/step - loss: 1.9413 - accuracy: 0.0277 - val_loss: 1.8544 - val_accuracy: 0.0017\n","Epoch 10/10\n","10/10 [==============================] - 28s 3s/step - loss: 1.9112 - accuracy: 0.0281 - val_loss: 1.9079 - val_accuracy: 0.0017\n","sava weight done..\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"yUVzi8sOueNI"},"execution_count":null,"outputs":[]}]}